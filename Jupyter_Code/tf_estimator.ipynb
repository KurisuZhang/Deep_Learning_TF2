{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf.estimator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOTquq5mEmByGcgObZUBy0e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LinCheungS/TensorFlow2_DL/blob/master/tf_estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5yXwgcjMzCm",
        "colab_type": "text"
      },
      "source": [
        "# tf.estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlY9ArCgM45a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfNiE1KbQk1m",
        "colab_type": "text"
      },
      "source": [
        "## 清洗可视化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7VzI9lbM0zE",
        "colab_type": "code",
        "outputId": "eaa97edc-70d2-4955-ad59-60f98cb33719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "row_data = pd.read_csv(\"aa.csv\")\n",
        "y_row_data= row_data.pop(\"Survived\")\n",
        "train_df, eval_df, y_train, y_eval = train_test_split(row_data, y_row_data)\n",
        "train_df = pd.DataFrame(train_df)\n",
        "eval_df = pd.DataFrame(eval_df)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "y_eval = pd.DataFrame(y_eval)\n",
        "print(train_df.shape,eval_df.shape,y_train.shape,y_eval.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(666, 8) (223, 8) (666, 1) (223, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m90Wgj1pKJ1O",
        "colab_type": "code",
        "outputId": "bd340e03-bbb2-4435-f71f-72579edd6204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_df.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 3594</td>\n",
              "      <td>8.05</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>345572</td>\n",
              "      <td>17.40</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C 7075</td>\n",
              "      <td>6.45</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass     Sex   Age  SibSp  Parch    Ticket   Fare Embarked\n",
              "481       3    male  50.0      0      0  A/5 3594   8.05        S\n",
              "558       3  female  36.0      1      0    345572  17.40        S\n",
              "817       3    male  43.0      0      0    C 7075   6.45        S"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzks5dyrPeha",
        "colab_type": "code",
        "outputId": "4f9bef4a-2d09-418b-c3a0-54c164e77faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>666.000000</td>\n",
              "      <td>666.000000</td>\n",
              "      <td>666.000000</td>\n",
              "      <td>666.000000</td>\n",
              "      <td>666.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.328829</td>\n",
              "      <td>29.878164</td>\n",
              "      <td>0.515015</td>\n",
              "      <td>0.372372</td>\n",
              "      <td>31.088343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.830786</td>\n",
              "      <td>12.834671</td>\n",
              "      <td>1.077696</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>47.638719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.646850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Pclass         Age       SibSp       Parch        Fare\n",
              "count  666.000000  666.000000  666.000000  666.000000  666.000000\n",
              "mean     2.328829   29.878164    0.515015    0.372372   31.088343\n",
              "std      0.830786   12.834671    1.077696    0.800049   47.638719\n",
              "min      1.000000    0.420000    0.000000    0.000000    0.000000\n",
              "25%      2.000000   22.000000    0.000000    0.000000    7.895800\n",
              "50%      3.000000   30.000000    0.000000    0.000000   14.454200\n",
              "75%      3.000000   35.000000    1.000000    0.000000   30.646850\n",
              "max      3.000000   71.000000    8.000000    6.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yee2zWF7Qsa3",
        "colab_type": "code",
        "outputId": "c2eb014c-be52-4c0e-ea9e-ae942d27a985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "# 年龄的分布图\n",
        "fig = plt.figure(figsize=[16,2.5])\n",
        "plt.subplot(141)\n",
        "train_df[\"Age\"].hist(bins = 20)\n",
        "# 性别的分别\n",
        "plt.subplot(142)\n",
        "train_df[\"Sex\"].value_counts().plot(kind='bar')\n",
        "# pclass的分别\n",
        "plt.subplot(143)\n",
        "train_df[\"Pclass\"].value_counts().plot(kind='bar')\n",
        "# 对于女性多少百分比获救,对于男性多少百分比\n",
        "plt.subplot(144)\n",
        "pd.concat([row_data, y_row_data], axis = 1).groupby(\"Sex\").Survived.mean().plot(kind='bar')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdab56d5fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x180 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wImSkHI9b29m",
        "colab_type": "text"
      },
      "source": [
        "## feature_column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9-xAmX7b6Ms",
        "colab_type": "text"
      },
      "source": [
        "特征列 通常用于对结构化数据实施特征工程时候使用, 使用特征列可以将类别特征转换为one-hot编码特征，将连续特征构建分桶特征."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x4B35tHUnha",
        "colab_type": "code",
        "outputId": "6887405d-b8e9-4e71-8fe8-9d1f08a05ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 数值数据,分类数据\n",
        "categorical_columns = ['Pclass', 'Sex', 'SibSp','Parch', 'Ticket','Embarked']\n",
        "numeric_columns = ['Age', 'Fare']\n",
        "feature_columns = []\n",
        "# 将categorical特征,封装成feature_columns\n",
        "for categorical_column in categorical_columns:\n",
        "    vocab = train_df[categorical_column].unique() # 生成所有的可能的数据\n",
        "    feature_columns.append(                    # 添加到feature_columns中\n",
        "        tf.feature_column.indicator_column(    # 生成onehot编码\n",
        "            tf.feature_column.categorical_column_with_vocabulary_list(  # 生成categorical_feature_column\n",
        "                categorical_column, vocab)))\n",
        "# 将numeric特征封装成feature_columns\n",
        "for numeric_column in numeric_columns:\n",
        "    feature_columns.append(       # 添加到feature_columns中\n",
        "        tf.feature_column.numeric_column(     # 生成numeric_feature_column\n",
        "            numeric_column, dtype=tf.float32))\n",
        "\n",
        "print(feature_columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Pclass', vocabulary_list=(1, 3, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='SibSp', vocabulary_list=(0, 1, 2, 8, 4, 3, 5), dtype=tf.int64, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Parch', vocabulary_list=(0, 5, 3, 1, 2, 4, 6), dtype=tf.int64, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Ticket', vocabulary_list=('5727', '11967', '2672', '113794', '330923', '350048', '113789', '382652', '371060', '2666', 'C.A. 33112', 'A/5 21171', '17421', '2668', 'PC 17604', '349236', '113806', 'A/5 21172', 'STON/O 2. 3101275', '349253', '113050', '364849', '2697', 'PP 9549', 'A/4 48871', '239855', '350404', '350050', '36568', 'W./C. 6608', '2623', '110564', '14973', '370370', 'P/PP 3381', 'PC 17599', '31418', 'A/5 2817', '19988', 'CA. 2343', '343095', '220845', '349213', '1601', 'A/4. 34244', '29751', 'PC 17572', '19947', '2649', '34218', '19950', '386525', '28424', 'C.A. 29566', 'PC 17612', '16988', '363291', '315094', '349212', '27267', '28551', 'SOTON/OQ 392089', '315097', 'A4. 54510', '244373', '368703', '347054', '367226', '3101295', 'S.O.C. 14879', '315082', '113800', '4136', '236171', '345780', '349225', '382651', '394140', '19928', '16966', 'C.A. 34651', '2662', '111426', '250644', 'SOTON/O2 3101272', '36973', '7534', '28664', 'F.C.C. 13528', 'SC/PARIS 2131', 'SOTON/O.Q. 3101305', '323951', 'C.A. 24580', '113781', 'SC/PARIS 2133', '21440', '110465', '349240', '244358', 'PC 17600', 'SC/AH 29037', '347466', '2629', '334912', 'SOTON/O.Q. 3101310', '19972', '4138', 'SOTON/OQ 392076', '19877', '113796', '2647', '236853', 'STON/O 2. 3101286', '113028', '4135', '2680', '2659', '364512', '110152', '367230', '27042', '4133', '19943', '113803', '26360', '35281', '239865', '347062', 'S.O.P. 1166', '248747', '12460', '349237', '111427', '243847', '2627', '345769', '111361', 'CA 2144', 'PC 17611', '239853', '19952', '248723', '113760', '11751', '36865', '2685', '111428', '3101281', '349909', 'PC 17609', '315037', 'S.W./PP 752', '2678', '36967', '330959', '2620', '350406', '248740', '2674', '2651', '349208', '347060', '233639', '250647', 'PC 17608', '29106', '231919', '364511', '349231', 'STON/O 2. 3101273', '349257', '113773', '347082', '4137', '349221', '35273', 'W./C. 6609', '13214', '13507', '2223', '29104', '2626', '349228', '349205', 'PC 17754', '370377', 'C.A. 6212', '233866', '7546', 'W.E.P. 5734', '345764', 'F.C.C. 13529', 'A/5 3540', '365222', '330980', '7545', '113776', 'A/5 3594', '240929', '350060', '2691', 'WE/P 5735', 'SC/PARIS 2167', '695', 'PC 17569', '349910', '370365', '248733', '349242', 'PC 17596', '349248', '2677', '244278', '248731', 'SOTON/O.Q. 3101306', '231945', '330958', 'C 7076', '244367', '113786', '347088', '219533', 'STON/O2. 3101271', '371110', '364499', '250653', '364516', '230080', 'C.A. 29178', '17464', '315096', '367655', '250643', '330935', 'SC 1748', '11771', '28665', '348123', '250655', '17453', '350025', '315086', 'PC 17475', '230433', '370369', '24160', '349207', '113059', '4579', '248727', '349217', '2683', '250649', '315151', '349227', '349222', '113798', '13049', 'W./C. 14263', '244310', '363294', 'A/4 45380', '370371', '112277', 'S.O./P.P. 3', 'SC/Paris 2163', '343120', 'A/5. 851', '36928', '36864', '11755', '367229', 'PC 17585', 'F.C.C. 13531', 'PC 17755', '364851', '349219', '13567', '234818', '384461', '111369', '28206', '112058', '111320', 'STON/O2. 3101279', '31027', '358585', '370373', 'C 17369', '347061', '374746', '350029', '112052', '237736', '237789', 'PC 17477', 'SOTON/OQ 3101317', '248738', '230434', 'S.C./PARIS 2079', '250646', '373450', 'SC/Paris 2123', '347083', '315153', 'SOTON/OQ 392086', 'PC 17757', '372622', '2661', '28220', '29103', 'A.5. 11206', 'C.A. 37671', 'C 4001', '347073', '350052', '113055', '392096', '9234', '315088', '2689', '11774', '376564', '2695', 'STON/O 2. 3101293', '113807', 'PP 4348', '2700', '250652', '2653', '349246', '350047', 'A/5. 3337', '29750', 'STON/O 2. 3101288', '347742', '347468', 'W./C. 14258', '347080', '349251', '350043', '376566', '112053', '349252', '7598', 'SOTON/OQ 392090', '345773', 'PC 17582', '14313', '371362', '2699', '364848', 'A./5. 2152', 'PC 17597', '26707', '35851', '113510', '19996', '3101298', '349254', '211536', 'SOTON/OQ 3101316', 'A/5. 2151', '12749', '3460', '349218', '230136', '2631', '330909', '368323', 'A/4. 39886', '315098', '341826', '3411', '347063', 'C.A. 29395', '2690', '347077', '113505', '14312', '2624', '348121', '11753', 'A/5. 13032', '3101277', 'STON/O 2. 3101292', '113787', '113503', '2648', '383121', '349239', '349912', '7267', '2926', 'STON/O 2. 3101274', 'CA. 2314', '2628', '330932', '2687', '112059', 'PC 17758', '370129', '3101265', '65303', '345779', 'SOTON/O.Q. 3101312', 'C.A./SOTON 34068', 'PC 17760', '3101276', '27849', '17465', '330931', '226875', 'C.A. 2315', '244361', '370375', '3101264', '347071', 'C.A. 2673', '2664', 'STON/O2. 3101290', 'STON/O2. 3101283', 'A./5. 3235', 'LINE', '345572', '2665', '13502', '11668', 'A/5. 10482', 'A/4. 20589', 'A/5 3902', '223596', '2686', '243880', '349215', 'SOTON/O.Q. 3101307', 'PC 17759', '347076', '347081', 'C.A. 5547', 'SCO/W 1585', '364846', 'PC 17590', '330877', '347085', '364506', 'SC/PARIS 2146', 'PC 17485', '2669', '349224', '29011', '349223', 'SW/PP 751', '33638', '36947', '11813', '226593', 'PC 17482', '335677', '13213', '113767', '12233', '36866', '7552', '110413', '2693', '343276', '335097', 'SOTON/O2 3101287', 'C.A. 31921', '2625', '3101278', '113788', '336439', '364850', '112379', '323592', '65306', 'A/5 2466', 'PC 17603', '17463', 'A/5. 3336', '347069', 'W./C. 6607', '345778', '363592', '349249', '345364', '367232', 'C.A. 18723', '112050', 'C 7077', '113501', '17474', '348124', '347743', '345770', '113804', 'SOTON/O.Q. 392078', '349206', '365226', '248698', '350034', '3474', 'A/5 3536', 'A.5. 18509', 'F.C. 12750', 'PC 17593', '349256', 'PC 17318', '374910', '345763', '113784', '229236', '345774', 'PC 17761', '2003', 'C.A. 33595', '345783', '347470', '113792', '65304', 'STON/O 2. 3101289', '8475', '250651', 'C.A. 34260', 'W/C 14208', 'S.P. 3464', '248706', '315093', '349201', '347087', '13568', 'STON/O 2. 3101294'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Embarked', vocabulary_list=('S', 'C', 'Q'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT7Oy_g4ZHZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 构建数据集\n",
        "def make_dataset(features, labels, batch_size = 32,training=True):\n",
        "    # 将dataframe构建成字典, 符合tensor_slices的调用, 将输入转换为数据集\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "    # 如果在训练模式下混淆并重复数据。\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "    # 传回一个batch\n",
        "    return dataset.batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrw6q6M4dnlL",
        "colab_type": "code",
        "outputId": "46b93635-1c33-43af-c617-49d0a982d6ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "train_dataset = make_dataset(train_df, y_train, batch_size = 3)\n",
        "for x, y in train_dataset.take(1):\n",
        "    print(x)\n",
        "    print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Pclass': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([3, 3, 3])>, 'Sex': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'male', b'male', b'female'], dtype=object)>, 'Age': <tf.Tensor: shape=(3,), dtype=float64, numpy=array([34., 41.,  5.])>, 'SibSp': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 2, 4])>, 'Parch': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 0, 2])>, 'Ticket': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'347080', b'350026', b'347077'], dtype=object)>, 'Fare': <tf.Tensor: shape=(3,), dtype=float64, numpy=array([14.4   , 14.1083, 31.3875])>, 'Embarked': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'S', b'S', b'S'], dtype=object)>}\n",
            "tf.Tensor(\n",
            "[[0]\n",
            " [0]\n",
            " [1]], shape=(3, 1), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpTJ_gugd_fR",
        "colab_type": "code",
        "outputId": "f8963a4c-08a4-4eae-8c1f-ce48958d251a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "# 将feature_column转成keras.layers.DenseFeature,以便喂给dataset\n",
        "for x, y in train_dataset.take(1):\n",
        "    gender_column = feature_columns[1]\n",
        "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())\n",
        "    print(\"可视化sex\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer dense_features_341 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "[[47.        1.        0.       ...  0.        0.        0.      ]\n",
            " [30.626179  1.        0.       ...  0.        0.        0.      ]\n",
            " [15.        0.        0.       ...  0.        0.        0.      ]]\n",
            "可视化sex\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAr-nALXiZ6e",
        "colab_type": "text"
      },
      "source": [
        "## premade estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcFj6HBOqzgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 构建数据集\n",
        "def make_dataset(features, labels, batch_size = 32,training=True):\n",
        "    # 将dataframe构建成字典, 符合tensor_slices的调用, 将输入转换为数据集\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "    # 如果在训练模式下混淆并重复数据。\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "    # 传回一个batch\n",
        "    return dataset.batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdtoVHpSqujF",
        "colab_type": "text"
      },
      "source": [
        "### BaselineClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXCuv3Fnqu7r",
        "colab_type": "code",
        "outputId": "a2ed7471-7b8d-496f-dc98-503dbaa41cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "baseline_estimator = tf.estimator.BaselineClassifier(n_classes = 2)\n",
        "baseline_estimator.train(input_fn = lambda : make_dataset(train_df, y_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpvak8c9i9\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpvak8c9i9', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[{{node IteratorGetNext}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-e1562a6e7d73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbaseline_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaselineClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbaseline_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1180\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1213\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1214\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_creation_timeout_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         log_step_count_steps=log_step_count_steps) as mon_sess:\n\u001b[0m\u001b[1;32m   1515\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[0;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs, save_checkpoint_steps, summary_dir, save_graph_def)\u001b[0m\n\u001b[1;32m    602\u001b[0m       \u001b[0msession_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m       stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    747\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \"\"\"\n\u001b[1;32m   1230\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         logging.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m       \u001b[0;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m       \u001b[0;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m       \u001b[0;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[0;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[1;32m    299\u001b[0m                            \"init_fn or local_init_op was given\")\n\u001b[1;32m    300\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[node IteratorGetNext (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/util.py:61) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node IteratorGetNext:\n IteratorV2 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/util.py:59)\n\nOriginal stack trace for 'IteratorGetNext':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-95-e1562a6e7d73>\", line 2, in <module>\n    baseline_estimator.train(input_fn = lambda : make_dataset(train_df, y_train))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 349, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1182, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1208, in _train_model_default\n    self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1044, in _get_features_and_labels_from_input_fn\n    self._call_input_fn(input_fn, mode))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/util.py\", line 61, in parse_input_fn_result\n    result = iterator.get_next()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 427, in get_next\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2377, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3327, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1791, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spPhrx2WzJxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0761fa4c-ce77-46e8-b463-bef819d99c83"
      },
      "source": [
        "baseline_estimator = tf.compat.v1.estimator.BaselineClassifier(n_classes = 2)\n",
        "baseline_estimator.train(input_fn = lambda : make_dataset(train_df, y_train), steps = 2000)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpmes_cq3v\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpmes_cq3v', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpmes_cq3v/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 22.18071, step = 0\n",
            "INFO:tensorflow:global_step/sec: 625.89\n",
            "INFO:tensorflow:loss = 22.595058, step = 100 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.185\n",
            "INFO:tensorflow:loss = 23.886248, step = 200 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.639\n",
            "INFO:tensorflow:loss = 23.284801, step = 300 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 961.871\n",
            "INFO:tensorflow:loss = 18.834442, step = 400 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 917.307\n",
            "INFO:tensorflow:loss = 21.174015, step = 500 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 880.768\n",
            "INFO:tensorflow:loss = 19.718784, step = 600 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 954.275\n",
            "INFO:tensorflow:loss = 20.199844, step = 700 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 949.735\n",
            "INFO:tensorflow:loss = 22.114391, step = 800 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 938.283\n",
            "INFO:tensorflow:loss = 21.658669, step = 900 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.518\n",
            "INFO:tensorflow:loss = 22.641193, step = 1000 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.951\n",
            "INFO:tensorflow:loss = 20.26471, step = 1100 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.581\n",
            "INFO:tensorflow:loss = 20.691906, step = 1200 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 934.853\n",
            "INFO:tensorflow:loss = 19.767715, step = 1300 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 906.89\n",
            "INFO:tensorflow:loss = 18.605026, step = 1400 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 947.043\n",
            "INFO:tensorflow:loss = 20.676682, step = 1500 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 916.501\n",
            "INFO:tensorflow:loss = 19.755226, step = 1600 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 968.834\n",
            "INFO:tensorflow:loss = 19.704733, step = 1700 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 993.184\n",
            "INFO:tensorflow:loss = 22.135345, step = 1800 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 976.439\n",
            "INFO:tensorflow:loss = 20.232767, step = 1900 (0.103 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmpmes_cq3v/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
            "INFO:tensorflow:Loss for final step: 21.172218.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.baseline.BaselineClassifier at 0x7fdab2e65cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cduY4UqazZHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "a0f9109b-292b-4f85-df38-5965edc08028"
      },
      "source": [
        "eval_result = baseline_estimator.evaluate(\n",
        "    input_fn=lambda: make_dataset(eval_df, y_eval, training=False))\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/head.py:642: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-05-07T15:42:52Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpmes_cq3v/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.42588s\n",
            "INFO:tensorflow:Finished evaluation at 2020-05-07-15:42:53\n",
            "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.6143498, accuracy_baseline = 0.6143498, auc = 0.5, auc_precision_recall = 0.6928251, average_loss = 0.66681707, global_step = 2000, label/mean = 0.38565022, loss = 21.242887, precision = 0.0, prediction/mean = 0.38057587, recall = 0.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /tmp/tmpmes_cq3v/model.ckpt-2000\n",
            "\n",
            "Test set accuracy: 0.614\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB6qw7fsqilV",
        "colab_type": "text"
      },
      "source": [
        "### estimator.DNNClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHSvJwTK1rHU",
        "colab_type": "code",
        "outputId": "9d0cb374-2402-46f5-d36e-a2e9bd4c3be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# 构建一个拥有两个隐层，隐藏节点分别为 30 和 10 的深度神经网络。\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    # 隐层所含结点数量分别为 30 和 10.\n",
        "    hidden_units=[100, 50, 10],\n",
        "    activation_fn = tf.nn.relu,\n",
        "    optimizer = 'Adam',\n",
        "    # 模型必须从三个类别中做出选择。\n",
        "    n_classes=2)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmphfl7az1e\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmphfl7az1e', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6wEhWMU17gL",
        "colab_type": "code",
        "outputId": "fa3e1b29-2b7f-46f1-ac24-b81f492ca922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 训练模型。\n",
        "classifier.train(\n",
        "    input_fn = lambda : make_dataset(train_df, y_train),\n",
        "    steps=2000)\n",
        "\n",
        "# INFO:tensorflow:Loss for final step: 0.50398713."
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmphfl7az1e/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 0.60879177, step = 0\n",
            "INFO:tensorflow:global_step/sec: 357.566\n",
            "INFO:tensorflow:loss = 0.359718, step = 100 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.59\n",
            "INFO:tensorflow:loss = 0.25484598, step = 200 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.781\n",
            "INFO:tensorflow:loss = 0.1564017, step = 300 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 539.681\n",
            "INFO:tensorflow:loss = 0.16107227, step = 400 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.59\n",
            "INFO:tensorflow:loss = 0.13024214, step = 500 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.828\n",
            "INFO:tensorflow:loss = 0.029164737, step = 600 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.352\n",
            "INFO:tensorflow:loss = 0.011233822, step = 700 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.999\n",
            "INFO:tensorflow:loss = 0.010397583, step = 800 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.496\n",
            "INFO:tensorflow:loss = 0.13778676, step = 900 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.761\n",
            "INFO:tensorflow:loss = 0.016619124, step = 1000 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.798\n",
            "INFO:tensorflow:loss = 0.01089839, step = 1100 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.078\n",
            "INFO:tensorflow:loss = 0.33944806, step = 1200 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.645\n",
            "INFO:tensorflow:loss = 0.09546553, step = 1300 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 540.003\n",
            "INFO:tensorflow:loss = 0.004606035, step = 1400 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.791\n",
            "INFO:tensorflow:loss = 0.047559008, step = 1500 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.827\n",
            "INFO:tensorflow:loss = 0.0011706039, step = 1600 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.427\n",
            "INFO:tensorflow:loss = 0.010630675, step = 1700 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.352\n",
            "INFO:tensorflow:loss = 0.0014010915, step = 1800 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 516.915\n",
            "INFO:tensorflow:loss = 0.0023192177, step = 1900 (0.196 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmphfl7az1e/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
            "INFO:tensorflow:Loss for final step: 0.00085702876.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7fdab27b7d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nahGNeqg2wBB",
        "colab_type": "code",
        "outputId": "0fe9158b-5f13-49b9-d7cd-4ce644b62ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: make_dataset(eval_df, y_eval, training=False))\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-05-07T15:44:24Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmphfl7az1e/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.60185s\n",
            "INFO:tensorflow:Finished evaluation at 2020-05-07-15:44:25\n",
            "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.7892377, accuracy_baseline = 0.6143498, auc = 0.8427686, auc_precision_recall = 0.78637123, average_loss = 0.70270556, global_step = 2000, label/mean = 0.38565022, loss = 0.7030547, precision = 0.7468355, prediction/mean = 0.3546011, recall = 0.68604654\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /tmp/tmphfl7az1e/model.ckpt-2000\n",
            "\n",
            "Test set accuracy: 0.789\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7Sk6lJP5Ate",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 只输入x\n",
        "def input_fn(features, batch_size=32):\n",
        "    \"\"\"An input function for prediction.\"\"\"\n",
        "    # 将输入转换为无标签数据集。\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "predict_x = eval_df[:3]\n",
        "# predictions是一个生成器\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn(predict_x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoXB9KKh5j58",
        "colab_type": "code",
        "outputId": "7a3f7b89-abc4-494e-868a-0886d843b758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "expected = [\"没生还\",\"生还\"]\n",
        "for pred in predictions:\n",
        "    class_id = pred['class_ids'][0]\n",
        "    probability = pred['probabilities'][class_id]\n",
        "    print(\"准确率:\",probability,expected[class_id])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmphfl7az1e/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "准确率: 0.9958247 生还\n",
            "准确率: 0.97009605 没生还\n",
            "准确率: 0.8441325 生还\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwwSIT5C8moO",
        "colab_type": "text"
      },
      "source": [
        "### LinearClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGxYFWgComhk",
        "colab_type": "code",
        "outputId": "3a011a92-2d5d-484c-ee66-0b13ec282619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
        "linear_est.train(input_fn = lambda : make_dataset(train_df, y_train),steps=2000)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp5_c6pugj\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp5_c6pugj', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:540: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp5_c6pugj/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 0.6931472, step = 0\n",
            "INFO:tensorflow:global_step/sec: 479.192\n",
            "INFO:tensorflow:loss = 0.5398778, step = 100 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 831.105\n",
            "INFO:tensorflow:loss = 0.5986965, step = 200 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 836.145\n",
            "INFO:tensorflow:loss = 0.31855386, step = 300 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 785.965\n",
            "INFO:tensorflow:loss = 0.42186978, step = 400 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.594\n",
            "INFO:tensorflow:loss = 0.34639332, step = 500 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 846.792\n",
            "INFO:tensorflow:loss = 0.33293298, step = 600 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 764.914\n",
            "INFO:tensorflow:loss = 0.24407251, step = 700 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.553\n",
            "INFO:tensorflow:loss = 0.3549033, step = 800 (0.121 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 879 vs previous value: 879. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 810.838\n",
            "INFO:tensorflow:loss = 0.2670607, step = 900 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 830.228\n",
            "INFO:tensorflow:loss = 0.32982284, step = 1000 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 825.08\n",
            "INFO:tensorflow:loss = 0.3900792, step = 1100 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 787.842\n",
            "INFO:tensorflow:loss = 0.17712538, step = 1200 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.167\n",
            "INFO:tensorflow:loss = 0.2473411, step = 1300 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 830.707\n",
            "INFO:tensorflow:loss = 0.26998597, step = 1400 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.434\n",
            "INFO:tensorflow:loss = 0.38451937, step = 1500 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 847.512\n",
            "INFO:tensorflow:loss = 0.32988113, step = 1600 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 839.212\n",
            "INFO:tensorflow:loss = 0.31076163, step = 1700 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 789.232\n",
            "INFO:tensorflow:loss = 0.33433792, step = 1800 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 825.277\n",
            "INFO:tensorflow:loss = 0.24323443, step = 1900 (0.121 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmp5_c6pugj/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
            "INFO:tensorflow:Loss for final step: 0.21077137.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x7fdab26327b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8uWGifVpDf2",
        "colab_type": "code",
        "outputId": "e0611e87-4b11-466b-ad72-cc030456c45d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "eval_result = linear_est.evaluate(\n",
        "    input_fn=lambda: make_dataset(eval_df, y_eval, training=False))\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-05-07T14:57:41Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp5_c6pugj/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.58184s\n",
            "INFO:tensorflow:Finished evaluation at 2020-05-07-14:57:41\n",
            "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.8206278, accuracy_baseline = 0.6233184, auc = 0.8785114, auc_precision_recall = 0.85824436, average_loss = 0.41634735, global_step = 2000, label/mean = 0.37668163, loss = 0.41649717, precision = 0.73913044, prediction/mean = 0.42481276, recall = 0.8095238\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /tmp/tmp5_c6pugj/model.ckpt-2000\n",
            "\n",
            "Test set accuracy: 0.821\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFEYMZQvo5VN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 只输入x\n",
        "def input_fn(features, batch_size=32):\n",
        "    \"\"\"An input function for prediction.\"\"\"\n",
        "    # 将输入转换为无标签数据集。\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "predict_x = eval_df[:3]\n",
        "# predictions是一个生成器\n",
        "predictions = linear_est.predict(input_fn=lambda: input_fn(predict_x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrSuO8nMpLTm",
        "colab_type": "code",
        "outputId": "e12fe27d-2a17-4aca-8e28-dbf0c17363c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "expected = [\"没生还\",\"生还\"]\n",
        "for pred in predictions:\n",
        "    class_id = pred['class_ids'][0]\n",
        "    probability = pred['probabilities'][class_id]\n",
        "    print(\"准确率:\",probability,expected[class_id])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp5_c6pugj/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "准确率: 0.83759606 没生还\n",
            "准确率: 0.92330354 没生还\n",
            "准确率: 0.9305453 没生还\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBzW8pWsz7uY",
        "colab_type": "text"
      },
      "source": [
        "## model_to_estimator(有问题)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ5En3aygOu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.DenseFeatures(feature_columns),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(2, activation='softmax'),\n",
        "])\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer = keras.optimizers.SGD(lr=0.01),\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjbT_3RVgxOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. model.fit \n",
        "# 2. model -> estimator -> train\n",
        "\n",
        "train_dataset = make_dataset(train_df, y_train)\n",
        "eval_dataset = make_dataset(eval_df, y_eval)\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "                    steps_per_epoch = 20,\n",
        "                    validation_steps = 8,\n",
        "                    validation_data = eval_dataset,\n",
        "                    epochs = 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg7_2pKLAdqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 构建数据集\n",
        "def make_dataset(features =train_df , labels=y_train, batch_size = 1,training=True):\n",
        "    # 将dataframe构建成字典, 符合tensor_slices的调用, 将输入转换为数据集\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "    # 如果在训练模式下混淆并重复数据。\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000)\n",
        "    # 传回一个batch\n",
        "    return dataset.batch(batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BW8vk-4dPo8",
        "colab_type": "code",
        "outputId": "84bc3b1f-20c2-42a2-8b99-bfb1ca5d3f97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "np.flatten(keras.layers.DenseFeatures(feature_columns)(i).numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-df86e2381563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'flatten'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCV843KnAb6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tempfile\n",
        "model_dir = tempfile.mkdtemp()\n",
        "keras_estimator = tf.keras.estimator.model_to_estimator(\n",
        "    keras_model=model, model_dir=model_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ivCKEtAIRH2",
        "colab_type": "code",
        "outputId": "6c90e593-05e7-4e34-b905-91acf11f7008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        }
      },
      "source": [
        "keras_estimator.train(input_fn=make_dataset(), steps=500)\n",
        "eval_result = keras_estimator.evaluate(input_fn=make_dataset(), steps=10)\n",
        "print('Eval result: {}'.format(eval_result))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1125\u001b[0m                                        \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m                                        sigcls=Signature)\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2193\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{!r} is not a callable object'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: <BatchDataset shapes: ({Pclass: (None,), Sex: (None,), Age: (None,), SibSp: (None,), Parch: (None,), Ticket: (None,), Fare: (None,), Embarked: (None,)}, (None, 1)), types: ({Pclass: tf.int64, Sex: tf.string, Age: tf.float64, SibSp: tf.int64, Parch: tf.int64, Ticket: tf.string, Fare: tf.float64, Embarked: tf.string}, tf.int64)> is not a callable object",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-887b20717012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0meval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Eval result: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1180\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m       features, labels, input_hooks = (\n\u001b[0;32m-> 1208\u001b[0;31m           self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))\n\u001b[0m\u001b[1;32m   1209\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m       estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;34m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     return estimator_util.parse_input_fn_result(\n\u001b[0;32m-> 1044\u001b[0;31m         self._call_input_fn(input_fn, mode))\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extract_batch_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_evaluated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[0;34m(self, input_fn, mode, input_context)\u001b[0m\n\u001b[1;32m   1121\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtakes\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \"\"\"\n\u001b[0;32m-> 1123\u001b[0;31m     \u001b[0minput_fn_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'mode'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/function_utils.py\u001b[0m in \u001b[0;36mfn_args\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_callable_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_bound_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m       \u001b[0;31m# If it's a bound method, it may or may not have a self/cls first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator_argspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_maybe_argspec_to_fullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_getfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m# else. So to be fully backwards compatible, we catch all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# possible exceptions here, and reraise a TypeError.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unsupported callable'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported callable"
          ]
        }
      ]
    }
  ]
}