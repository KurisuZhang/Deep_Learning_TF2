{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "tensorflow1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LinCheungS/TensorFlow2_DL/blob/master/tensorflow1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3iyzELU8FtY",
        "colab_type": "code",
        "colab": {},
        "outputId": "87807263-e089-4eaa-d412-00f4c02ada4f"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.2\n",
            "pandas 0.24.2\n",
            "sklearn 0.20.3\n",
            "tensorflow 1.13.1\n",
            "tensorflow._api.v1.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoziACbx8QQ9",
        "colab_type": "text"
      },
      "source": [
        "## tf1_customized_estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL8cxI5S8Ftb",
        "colab_type": "code",
        "colab": {},
        "outputId": "443d0567-2229-43ce-c5bd-23fe7e2f3ff1"
      },
      "source": [
        "# https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
        "# https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
        "train_file = \"./data/titanic/train.csv\"\n",
        "eval_file = \"./data/titanic/eval.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_file)\n",
        "eval_df = pd.read_csv(eval_file)\n",
        "\n",
        "print(train_df.head())\n",
        "print(eval_df.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
            "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
            "1         1  female  38.0                   1      0  71.2833  First        C   \n",
            "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
            "3         1  female  35.0                   1      0  53.1000  First        C   \n",
            "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
            "\n",
            "   embark_town alone  \n",
            "0  Southampton     n  \n",
            "1    Cherbourg     n  \n",
            "2  Southampton     y  \n",
            "3  Southampton     n  \n",
            "4   Queenstown     y  \n",
            "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
            "0         0    male  35.0                   0      0   8.0500   Third   \n",
            "1         0    male  54.0                   0      0  51.8625   First   \n",
            "2         1  female  58.0                   0      0  26.5500   First   \n",
            "3         1  female  55.0                   0      0  16.0000  Second   \n",
            "4         1    male  34.0                   0      0  13.0000  Second   \n",
            "\n",
            "      deck  embark_town alone  \n",
            "0  unknown  Southampton     y  \n",
            "1        E  Southampton     y  \n",
            "2        C  Southampton     y  \n",
            "3  unknown  Southampton     y  \n",
            "4        D  Southampton     y  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NweZvUW_8Fte",
        "colab_type": "code",
        "colab": {},
        "outputId": "c8a8732a-30bb-481b-e20e-b1bf4ffad3ce"
      },
      "source": [
        "y_train = train_df.pop('survived')\n",
        "y_eval = eval_df.pop('survived')\n",
        "\n",
        "print(train_df.head())\n",
        "print(eval_df.head())\n",
        "print(y_train.head())\n",
        "print(y_eval.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
            "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
            "1  female  38.0                   1      0  71.2833  First        C   \n",
            "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
            "3  female  35.0                   1      0  53.1000  First        C   \n",
            "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
            "\n",
            "   embark_town alone  \n",
            "0  Southampton     n  \n",
            "1    Cherbourg     n  \n",
            "2  Southampton     y  \n",
            "3  Southampton     n  \n",
            "4   Queenstown     y  \n",
            "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
            "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
            "1    male  54.0                   0      0  51.8625   First        E   \n",
            "2  female  58.0                   0      0  26.5500   First        C   \n",
            "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
            "4    male  34.0                   0      0  13.0000  Second        D   \n",
            "\n",
            "   embark_town alone  \n",
            "0  Southampton     y  \n",
            "1  Southampton     y  \n",
            "2  Southampton     y  \n",
            "3  Southampton     y  \n",
            "4  Southampton     y  \n",
            "0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: survived, dtype: int64\n",
            "0    0\n",
            "1    0\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "Name: survived, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBWfxSnM8Ftg",
        "colab_type": "code",
        "colab": {},
        "outputId": "349b358f-b2c2-47c9-ae98-93850d008af5"
      },
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.631308</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.379585</td>\n",
              "      <td>34.385399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.511818</td>\n",
              "      <td>1.151090</td>\n",
              "      <td>0.792999</td>\n",
              "      <td>54.597730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age  n_siblings_spouses       parch        fare\n",
              "count  627.000000          627.000000  627.000000  627.000000\n",
              "mean    29.631308            0.545455    0.379585   34.385399\n",
              "std     12.511818            1.151090    0.792999   54.597730\n",
              "min      0.750000            0.000000    0.000000    0.000000\n",
              "25%     23.000000            0.000000    0.000000    7.895800\n",
              "50%     28.000000            0.000000    0.000000   15.045800\n",
              "75%     35.000000            1.000000    0.000000   31.387500\n",
              "max     80.000000            8.000000    5.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bJ40fqm8Ftj",
        "colab_type": "code",
        "colab": {},
        "outputId": "118b70fe-ee35-4b0f-a93c-ae963a6efa9d"
      },
      "source": [
        "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
        "                       'deck', 'embark_town', 'alone']\n",
        "numeric_columns = ['age', 'fare']\n",
        "\n",
        "feature_columns = []\n",
        "for categorical_column in categorical_columns:\n",
        "    vocab = train_df[categorical_column].unique()\n",
        "    print(categorical_column, vocab)\n",
        "    feature_columns.append(\n",
        "        tf.feature_column.indicator_column(\n",
        "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "                categorical_column, vocab)))\n",
        "\n",
        "for categorical_column in numeric_columns:\n",
        "    feature_columns.append(\n",
        "        tf.feature_column.numeric_column(\n",
        "            categorical_column, dtype=tf.float32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex ['male' 'female']\n",
            "n_siblings_spouses [1 0 3 4 2 5 8]\n",
            "parch [0 1 2 5 3 4]\n",
            "class ['Third' 'First' 'Second']\n",
            "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
            "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
            "alone ['n' 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMWQM5l68Ftl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(data_df, label_df, epochs = 10, shuffle = True,\n",
        "                 batch_size = 32):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (dict(data_df), label_df))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
        "    return dataset.make_one_shot_iterator().get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q1KIiQ78Ftn",
        "colab_type": "code",
        "colab": {},
        "outputId": "92b67eb5-d4e0-43bd-c358-2e75611415b3"
      },
      "source": [
        "output_dir = \"customized_estimator\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "def model_fn(features, labels, mode, params):\n",
        "    # model runtime state: Train, Eval, Predict\n",
        "    input_for_next_layer = tf.feature_column.input_layer(\n",
        "        features, params['feature_columns'])\n",
        "    for n_unit in params['hidden_units']:\n",
        "        input_for_next_layer = tf.layers.dense(input_for_next_layer,\n",
        "                                               units = n_unit,\n",
        "                                               activation = tf.nn.relu)\n",
        "    logits = tf.layers.dense(input_for_next_layer,\n",
        "                             params['n_classes'],\n",
        "                             activation = None)\n",
        "    predicted_classes = tf.argmax(logits, 1)\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        predictions = {\n",
        "            \"class_ids\": predicted_classes[:, tf.newaxis],\n",
        "            \"probabilities\": tf.nn.softmax(logits),\n",
        "            \"logits\": logits\n",
        "        }\n",
        "        return tf.estimator.EstimatorSpec(mode,\n",
        "                                          predictions = predictions)\n",
        "    \n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels,\n",
        "                                                  logits = logits)\n",
        "    accuracy = tf.metrics.accuracy(labels = labels,\n",
        "                                   predictions = predicted_classes,\n",
        "                                   name = \"acc_op\")\n",
        "    metrics = {\"accuracy\": accuracy}\n",
        "    if mode == tf.estimator.ModeKeys.EVAL:\n",
        "        return tf.estimator.EstimatorSpec(mode, loss = loss,\n",
        "                                          eval_metric_ops = metrics)\n",
        "    optimizer = tf.train.AdamOptimizer()\n",
        "    train_op = optimizer.minimize(\n",
        "        loss, global_step = tf.train.get_global_step())\n",
        "    return tf.estimator.EstimatorSpec(mode, loss = loss,\n",
        "                                      train_op = train_op)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "    model_fn = model_fn,\n",
        "    model_dir = output_dir,\n",
        "    params = {\n",
        "        \"feature_columns\": feature_columns,\n",
        "        \"hidden_units\": [100, 100],\n",
        "        \"n_classes\": 2\n",
        "    })\n",
        "estimator.train(input_fn = lambda : make_dataset(\n",
        "    train_df, y_train, epochs = 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'customized_estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12daf3080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column.py:205: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column.py:2121: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column.py:206: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column.py:205: IndicatorColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column.py:2121: IndicatorColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4295: VocabularyListCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column.py:2121: VocabularyListCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/ops/lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4266: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4321: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From <ipython-input-7-c57751d6dcfc>:12: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into customized_estimator/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.9022088, step = 1\n",
            "INFO:tensorflow:global_step/sec: 301.616\n",
            "INFO:tensorflow:loss = 0.29633158, step = 101 (0.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.298\n",
            "INFO:tensorflow:loss = 0.6143039, step = 201 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 564.455\n",
            "INFO:tensorflow:loss = 0.32041603, step = 301 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.953\n",
            "INFO:tensorflow:loss = 0.40293896, step = 401 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 583.142\n",
            "INFO:tensorflow:loss = 0.3103894, step = 501 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.033\n",
            "INFO:tensorflow:loss = 0.5766603, step = 601 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.618\n",
            "INFO:tensorflow:loss = 0.34097248, step = 701 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.415\n",
            "INFO:tensorflow:loss = 0.25038648, step = 801 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.263\n",
            "INFO:tensorflow:loss = 0.505088, step = 901 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 465.56\n",
            "INFO:tensorflow:loss = 0.44969255, step = 1001 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 443.408\n",
            "INFO:tensorflow:loss = 0.24732417, step = 1101 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 427.855\n",
            "INFO:tensorflow:loss = 0.34562913, step = 1201 (0.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.927\n",
            "INFO:tensorflow:loss = 0.27141798, step = 1301 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.317\n",
            "INFO:tensorflow:loss = 0.6561841, step = 1401 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 516.836\n",
            "INFO:tensorflow:loss = 0.40642688, step = 1501 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.462\n",
            "INFO:tensorflow:loss = 0.32950634, step = 1601 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.788\n",
            "INFO:tensorflow:loss = 0.47663295, step = 1701 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 526.901\n",
            "INFO:tensorflow:loss = 0.4040637, step = 1801 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 621.311\n",
            "INFO:tensorflow:loss = 0.34504694, step = 1901 (0.161 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1960 into customized_estimator/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.15136214.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x12da60ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4mixR638Ftq",
        "colab_type": "code",
        "colab": {},
        "outputId": "3cc548d1-6c94-463d-eb4b-2ef76a50ef92"
      },
      "source": [
        "estimator.evaluate(lambda : make_dataset(\n",
        "    eval_df, y_eval, epochs = 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-06-12T13:50:23Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from customized_estimator/model.ckpt-1960\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-06-12-13:50:23\n",
            "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.7916667, global_step = 1960, loss = 0.5161865\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: customized_estimator/model.ckpt-1960\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7916667, 'loss': 0.5161865, 'global_step': 1960}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I9wvHE58Fts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tIxgoGL8UBZ",
        "colab_type": "text"
      },
      "source": [
        "## tf1_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOhBKfZ28Ftu",
        "colab_type": "code",
        "colab": {},
        "outputId": "eef16456-6167-4d06-b55d-7f7ea9b304a5"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.2\n",
            "pandas 0.24.2\n",
            "sklearn 0.20.3\n",
            "tensorflow 1.13.1\n",
            "tensorflow._api.v1.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4UbQOdT8Ftw",
        "colab_type": "code",
        "colab": {},
        "outputId": "5f7e400c-8286-46a4-add2-9538352a774c"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
        "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
        "\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 28, 28) (5000,)\n",
            "(55000, 28, 28) (55000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6mQU81U8Fty",
        "colab_type": "code",
        "colab": {},
        "outputId": "46f18126-9b7e-411d-df37-89363c906623"
      },
      "source": [
        "print(np.max(x_train), np.min(x_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI1zjUnf8Ft2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = (x - u) / std\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# x_train: [None, 28, 28] -> [None, 784]\n",
        "x_train_scaled = scaler.fit_transform(\n",
        "    x_train.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
        "x_valid_scaled = scaler.transform(\n",
        "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
        "x_test_scaled = scaler.transform(\n",
        "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
        "\n",
        "y_train = np.asarray(y_train, dtype = np.int64)\n",
        "y_valid = np.asarray(y_valid, dtype = np.int64)\n",
        "y_test = np.asarray(y_test, dtype = np.int64)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIfmx2wH8Ft5",
        "colab_type": "code",
        "colab": {},
        "outputId": "aafbe5d7-4ab5-4c8c-b911-b2fa93eee494"
      },
      "source": [
        "print(np.max(x_train_scaled), np.min(x_train_scaled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.023144 -0.8105139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM6F0fmI8Ft7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(images, labels, epochs, batch_size, shuffle = True):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbok-ZPH8Ft9",
        "colab_type": "code",
        "colab": {},
        "outputId": "cc569e6a-1876-491f-da74-b340c64d9a6b"
      },
      "source": [
        "batch_size = 20\n",
        "epochs = 10\n",
        "dataset = make_dataset(x_train_scaled, y_train,\n",
        "                       epochs = epochs,\n",
        "                       batch_size = batch_size)\n",
        "for data, label in dataset.take(1):\n",
        "    print(data)\n",
        "    print(label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "dataset.__iter__() is only supported when eager execution is enabled.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-64c99b9fccb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                        \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        batch_size = batch_size)\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       raise RuntimeError(\"dataset.__iter__() is only supported when eager \"\n\u001b[0m\u001b[1;32m    207\u001b[0m                          \"execution is enabled.\")\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: dataset.__iter__() is only supported when eager execution is enabled."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrmP6Ckx8Ft_",
        "colab_type": "code",
        "colab": {},
        "outputId": "7796e0b7-1895-48b3-e16f-387abfb07e36"
      },
      "source": [
        "batch_size = 20\n",
        "epochs = 10\n",
        "dataset = make_dataset(x_train_scaled, y_train,\n",
        "                       epochs = epochs,\n",
        "                       batch_size = batch_size)\n",
        "# 1. auto initialization\n",
        "# 2. can't be re-initialized. make_initializable_iterator\n",
        "dataset_iter = dataset.make_one_shot_iterator()\n",
        "x, y = dataset_iter.get_next()\n",
        "with tf.Session() as sess:\n",
        "    x_val, y_val = sess.run([x, y])\n",
        "    print(x_val.shape)\n",
        "    print(y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 784)\n",
            "(20,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nygT2QSt8FuB",
        "colab_type": "code",
        "colab": {},
        "outputId": "2dcc87b3-fa55-48de-d54e-237b7a654eb2"
      },
      "source": [
        "hidden_units = [100, 100]\n",
        "class_num = 10\n",
        "\n",
        "input_for_next_layer = x\n",
        "for hidden_unit in hidden_units:\n",
        "    input_for_next_layer = tf.layers.dense(input_for_next_layer,\n",
        "                                           hidden_unit,\n",
        "                                           activation=tf.nn.relu)\n",
        "logits = tf.layers.dense(input_for_next_layer,\n",
        "                         class_num)\n",
        "# last_hidden_output * W(logits) -> softmax -> prob\n",
        "# 1. logit -> softmax -> prob\n",
        "# 2. labels -> one_hot\n",
        "# 3. calculate cross entropy\n",
        "loss = tf.losses.sparse_softmax_cross_entropy(labels = y,\n",
        "                                              logits = logits)\n",
        "# get accuracy.\n",
        "prediction = tf.argmax(logits, 1)\n",
        "correct_prediction = tf.equal(prediction, y)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
        "\n",
        "train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-549d3d0bc7bb>:8: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQXgUR_d8FuD",
        "colab_type": "code",
        "colab": {},
        "outputId": "e9f4f3e9-689b-4426-8a11-6e101deb179b"
      },
      "source": [
        "print(x)\n",
        "print(logits)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"IteratorGetNext:0\", shape=(?, 784), dtype=float32)\n",
            "Tensor(\"dense_2/BiasAdd:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV-yGLiU8FuF",
        "colab_type": "code",
        "colab": {},
        "outputId": "9e131e03-21b0-4d1f-c06b-19649cd55691"
      },
      "source": [
        "# session\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "train_steps_per_epoch = x_train.shape[0] // batch_size\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(epochs):\n",
        "        for step in range(train_steps_per_epoch):\n",
        "            loss_val, accuracy_val, _ = sess.run(\n",
        "                [loss, accuracy, train_op])\n",
        "            print('\\r[Train] epoch: %d, step: %d, loss: %3.5f, accuracy: %2.2f' % (\n",
        "                epoch, step, loss_val, accuracy_val), end=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Train] epoch: 9, step: 2749, loss: 0.21062, accuracy: 0.90"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U71R_ObX8FuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti-06jdL8abA",
        "colab_type": "text"
      },
      "source": [
        "## dense_network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DfjRfcG8FuJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "18532cac-c1f9-4685-eda3-f5ec904a0e8c"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.2\n",
            "pandas 0.24.2\n",
            "sklearn 0.20.3\n",
            "tensorflow 1.13.1\n",
            "tensorflow._api.v1.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7P6ciUB8FuL",
        "colab_type": "code",
        "colab": {},
        "outputId": "d4fdc1f2-af95-4932-9165-f54bdc36ae18"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
        "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
        "\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 28, 28) (5000,)\n",
            "(55000, 28, 28) (55000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EWby-e78FuM",
        "colab_type": "code",
        "colab": {},
        "outputId": "f831a30d-ac7b-4c95-b8c7-29477024d191"
      },
      "source": [
        "print(np.max(x_train), np.min(x_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pp2XUG88FuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = (x - u) / std\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# x_train: [None, 28, 28] -> [None, 784]\n",
        "x_train_scaled = scaler.fit_transform(\n",
        "    x_train.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
        "x_valid_scaled = scaler.transform(\n",
        "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
        "x_test_scaled = scaler.transform(\n",
        "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9bbpPyR8FuR",
        "colab_type": "code",
        "colab": {},
        "outputId": "6823331b-5b92-4507-f017-eccfe5aa245b"
      },
      "source": [
        "print(np.max(x_train_scaled), np.min(x_train_scaled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.023144 -0.8105139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mywGcwSg8FuT",
        "colab_type": "code",
        "colab": {},
        "outputId": "0c89c98b-7d1f-4e81-caa2-f1f44a47e726"
      },
      "source": [
        "hidden_units = [100, 100]\n",
        "class_num = 10\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 28 * 28])\n",
        "y = tf.placeholder(tf.int64, [None])\n",
        "\n",
        "input_for_next_layer = x\n",
        "for hidden_unit in hidden_units:\n",
        "    input_for_next_layer = tf.layers.dense(input_for_next_layer,\n",
        "                                           hidden_unit,\n",
        "                                           activation=tf.nn.relu)\n",
        "logits = tf.layers.dense(input_for_next_layer,\n",
        "                         class_num)\n",
        "# last_hidden_output * W(logits) -> softmax -> prob\n",
        "# 1. logit -> softmax -> prob\n",
        "# 2. labels -> one_hot\n",
        "# 3. calculate cross entropy\n",
        "loss = tf.losses.sparse_softmax_cross_entropy(labels = y,\n",
        "                                              logits = logits)\n",
        "# get accuracy.\n",
        "prediction = tf.argmax(logits, 1)\n",
        "correct_prediction = tf.equal(prediction, y)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
        "\n",
        "train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-76fc28fa9449>:11: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BpMZlmJ8FuV",
        "colab_type": "code",
        "colab": {},
        "outputId": "26e90e7d-51fa-4da6-eb9a-30a69625c8c2"
      },
      "source": [
        "print(x)\n",
        "print(logits)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32)\n",
            "Tensor(\"dense_2/BiasAdd:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEZbHSzI8FuX",
        "colab_type": "code",
        "colab": {},
        "outputId": "ee50d0df-8950-4918-f84e-44e20d9d5ede"
      },
      "source": [
        "# session\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "batch_size = 20\n",
        "epochs = 10\n",
        "train_steps_per_epoch = x_train.shape[0] // batch_size\n",
        "valid_steps = x_valid.shape[0] // batch_size\n",
        "\n",
        "def eval_with_sess(sess, x, y, accuracy, images, labels, batch_size):\n",
        "    eval_steps = images.shape[0] // batch_size\n",
        "    eval_accuracies = []\n",
        "    for step in range(eval_steps):\n",
        "        batch_data = images[step * batch_size : (step+1) * batch_size]\n",
        "        batch_label = labels[step * batch_size : (step+1) * batch_size]\n",
        "        accuracy_val = sess.run(accuracy,\n",
        "                                feed_dict = {\n",
        "                                    x: batch_data,\n",
        "                                    y: batch_label\n",
        "                                })\n",
        "        eval_accuracies.append(accuracy_val)\n",
        "    return np.mean(eval_accuracies)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(epochs):\n",
        "        for step in range(train_steps_per_epoch):\n",
        "            batch_data = x_train_scaled[\n",
        "                step * batch_size : (step+1) * batch_size]\n",
        "            batch_label = y_train[\n",
        "                step * batch_size : (step+1) * batch_size]\n",
        "            loss_val, accuracy_val, _ = sess.run(\n",
        "                [loss, accuracy, train_op],\n",
        "                feed_dict = {\n",
        "                    x: batch_data,\n",
        "                    y: batch_label\n",
        "                })\n",
        "            print('\\r[Train] epoch: %d, step: %d, loss: %3.5f, accuracy: %2.2f' % (\n",
        "                epoch, step, loss_val, accuracy_val), end=\"\")\n",
        "        valid_accuracy = eval_with_sess(sess, x, y, accuracy,\n",
        "                                        x_valid_scaled, y_valid,\n",
        "                                        batch_size)\n",
        "        print(\"\\t[Valid] acc: %2.2f\" % (valid_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Train] epoch: 0, step: 2749, loss: 0.29409, accuracy: 0.85\t[Valid] acc: 0.86\n",
            "[Train] epoch: 1, step: 2749, loss: 0.23783, accuracy: 0.90\t[Valid] acc: 0.87\n",
            "[Train] epoch: 2, step: 2749, loss: 0.16557, accuracy: 0.90\t[Valid] acc: 0.87\n",
            "[Train] epoch: 3, step: 2749, loss: 0.16518, accuracy: 0.85\t[Valid] acc: 0.88\n",
            "[Train] epoch: 4, step: 2749, loss: 0.18367, accuracy: 0.90\t[Valid] acc: 0.88\n",
            "[Train] epoch: 5, step: 2749, loss: 0.18992, accuracy: 0.95\t[Valid] acc: 0.88\n",
            "[Train] epoch: 6, step: 2749, loss: 0.13003, accuracy: 0.95\t[Valid] acc: 0.88\n",
            "[Train] epoch: 7, step: 2749, loss: 0.19065, accuracy: 0.95\t[Valid] acc: 0.89\n",
            "[Train] epoch: 8, step: 2749, loss: 0.12379, accuracy: 0.90\t[Valid] acc: 0.88\n",
            "[Train] epoch: 9, step: 2749, loss: 0.11657, accuracy: 0.95\t[Valid] acc: 0.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSvPf_oz8FuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m10dlAa8i4E",
        "colab_type": "text"
      },
      "source": [
        "## initialized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQeKxF-98Fub",
        "colab_type": "code",
        "colab": {},
        "outputId": "cb1ddb1b-aed3-4937-c51e-0679ac8a518c"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.2\n",
            "pandas 0.24.2\n",
            "sklearn 0.20.3\n",
            "tensorflow 1.13.1\n",
            "tensorflow._api.v1.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZpDoud88Fue",
        "colab_type": "code",
        "colab": {},
        "outputId": "042975d2-8b58-46de-86a5-5efaeda34a5d"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
        "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
        "\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 28, 28) (5000,)\n",
            "(55000, 28, 28) (55000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GMk0NtE8Fug",
        "colab_type": "code",
        "colab": {},
        "outputId": "1cc93f16-dd8d-4b69-d993-45639aa247b3"
      },
      "source": [
        "print(np.max(x_train), np.min(x_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQmqyXZ48Fui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = (x - u) / std\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# x_train: [None, 28, 28] -> [None, 784]\n",
        "x_train_scaled = scaler.fit_transform(\n",
        "    x_train.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
        "x_valid_scaled = scaler.transform(\n",
        "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
        "x_test_scaled = scaler.transform(\n",
        "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28 * 28)\n",
        "\n",
        "y_train = np.asarray(y_train, dtype = np.int64)\n",
        "y_valid = np.asarray(y_valid, dtype = np.int64)\n",
        "y_test = np.asarray(y_test, dtype = np.int64)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB_JJSAx8Fuk",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9c758d8-b615-49ea-ba4b-24ffcfbc239b"
      },
      "source": [
        "print(np.max(x_train_scaled), np.min(x_train_scaled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.023144 -0.8105139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFFAFPI68Fum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(images, labels, epochs, batch_size, shuffle = True):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HyNKYCM8Fuo",
        "colab_type": "code",
        "colab": {},
        "outputId": "cad1e14f-aa44-4ded-c628-9b7ab8c26709"
      },
      "source": [
        "batch_size = 20\n",
        "epochs = 10\n",
        "\n",
        "images_placeholder = tf.placeholder(tf.float32, [None, 28 * 28])\n",
        "labels_placeholder = tf.placeholder(tf.int64, (None,))\n",
        "\n",
        "dataset = make_dataset(images_placeholder, labels_placeholder,\n",
        "                       epochs = epochs,\n",
        "                       batch_size = batch_size)\n",
        "\n",
        "dataset_iter = dataset.make_initializable_iterator()\n",
        "x, y = dataset_iter.get_next()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(dataset_iter.initializer,\n",
        "             feed_dict = {\n",
        "                 images_placeholder: x_train_scaled,\n",
        "                 labels_placeholder: y_train\n",
        "             })\n",
        "    x_val, y_val = sess.run([x, y])\n",
        "    print(x_val.shape)\n",
        "    print(y_val.shape)\n",
        "    sess.run(dataset_iter.initializer,\n",
        "             feed_dict = {\n",
        "                 images_placeholder: x_valid_scaled,\n",
        "                 labels_placeholder: y_valid,\n",
        "             })\n",
        "    x_val, y_val = sess.run([x, y])\n",
        "    print(x_val.shape)\n",
        "    print(y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/zhangyx/workspace/environments/tf_py3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "(20, 784)\n",
            "(20,)\n",
            "(20, 784)\n",
            "(20,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeJueZRc8Fuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}